---
title: "SEA rsfcMRI - Longitudinal Descriptives"
author: "John Flournoy"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{css, echo=FALSE}
@import url('https://fonts.googleapis.com/css?family=Didact+Gothic&display=swap');
@import url('https://fonts.googleapis.com/css?family=Fira+Code&display=swap');
body{
  font-family: 'Didact Gothic',  sans-serif;
}
pre code {
  font-family: 'Fira Code',  monospace;
}
```

```{r setup, include=FALSE}
library(ggplot2)
library(data.table)
library(dplyr)
library(tidyr)
library(showtext)
#{.tabset}

font_add_google("Didact Gothic", "Didact Gothic")
showtext_auto()

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
#https://www.instagram.com/p/CC3EvmLgt2m/?utm_source=ig_web_copy_link
apal <- paste0('#',c('2C2B2B', 'F9773B', 'FFEA8C', '1389E6', 'D2E5E7'))
jftheme <- theme_minimal() +  
    theme(text = element_text(family = 'Didact Gothic', size = 14),
          panel.background = element_rect(fill = apal[[5]], size = 0, color = apal[[2]]),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(), 
          strip.background = element_rect(fill = apal[[3]], size = 0),
          strip.text = element_text(color = '#222222'),
          axis.text =  element_text(color = apal[[1]]), axis.title = element_text(color = apal[[1]]))
knitr::read_chunk('collect_data.R')
```

# Load the data

Starting with the Schaefer 400-parcel, 7 network atlas.

```{r collect_data}
```

Retain just within-network connectivity. Also, Fisher-z transform the correlations for analyses. One small detail that is important here is that we keep network connectivity for same-hemisphere parcels only.

```{r}
sea_schaefer400_7_withinnet <- copy(adt_labels)

sub_regex <- '[LR]H_[A-Za-z]+_*(.*)'
net_regex <- '[LR]H_([A-Za-z]+)_*(?:.*)'
hem_regex <- '([LR]H)_[A-Za-z]+_*(?:.*)'
sea_schaefer400_7_withinnet_nets <- distinct(sea_schaefer400_7_withinnet, network1)
sea_schaefer400_7_withinnet_nets[, sub1 := gsub(sub_regex, '\\1', network1)]
sea_schaefer400_7_withinnet_nets[, net1 := gsub(net_regex, '\\1', network1)]
sea_schaefer400_7_withinnet_nets[, hem1 := gsub(hem_regex, '\\1', network1)]
setkey(sea_schaefer400_7_withinnet, network1)
setkey(sea_schaefer400_7_withinnet_nets, network1)
sea_schaefer400_7_withinnet <- sea_schaefer400_7_withinnet_nets[sea_schaefer400_7_withinnet]

setnames(sea_schaefer400_7_withinnet_nets, c('network2', 'sub2', 'net2', 'hem2'))
setkey(sea_schaefer400_7_withinnet, network2)
setkey(sea_schaefer400_7_withinnet_nets, network2)
sea_schaefer400_7_withinnet <- sea_schaefer400_7_withinnet_nets[sea_schaefer400_7_withinnet]

sea_schaefer400_7_withinnet <- sea_schaefer400_7_withinnet[net1 == net2 & hem1 == hem2]
sea_schaefer400_7_withinnet[, c('network1', 'network2') := NULL]
sea_schaefer400_7_withinnet[, z := atanh(r)]
sea_schaefer400_7_withinnet[, H := dplyr::case_when(hem1 == 'RH' ~ -1,
                                                    hem1 == 'LH' ~ 1)]
if(!dim(distinct(sea_schaefer400_7_withinnet, net1, net2, hem1, hem2))[[1]] == 14){
  stop('Incorrect number of networks')
}
```

# Some QC {.tabset}

Density of functional connectivity (pearson correlation) for each participant, for each subject, overlayed on the density for all sessions and participants.

```{r}
#Generate group-level density
agg_mean <- mean(sea_schaefer400_7_withinnet$z)
agg_sd <- sd(sea_schaefer400_7_withinnet$z)
scalez <- (sea_schaefer400_7_withinnet$z - agg_mean) / agg_sd
density_agg <- density(scalez)
sea_schaefer400_densplot_agg <- data.table(x = density_agg$x,
                                           x_on_z = density_agg$x * agg_sd + agg_mean,
                                           y = density_agg$y)
#Generate per-participant-session densities
sea_schaefer400_MSD <- sea_schaefer400_7_withinnet[, list(mean = mean(z),
                                                          sd = sd(z)), 
                                                   by = c('id', 'sess')]
sea_schaefer400_densplot <- sea_schaefer400_MSD[sea_schaefer400_7_withinnet, 
                                                on = c('id', 'sess')]
sea_schaefer400_densplot[, scalez := (z - mean)/sd]
sea_schaefer400_densplot <- 
  sea_schaefer400_MSD[sea_schaefer400_densplot[, list(x = density(scalez)$x,
                                                      y = density(scalez)$y), 
                                               by = c('id', 'sess')],
                      on = c('id', 'sess')][, x_on_z := sd*x + mean]
```

```{r, results = 'asis', fig.width=8, fig.height=8}
u_ids <- unique(sea_schaefer400_densplot$id)
for(an_id in u_ids){
  cat(paste0('\n\n## ', an_id, '\n\n'))
  
  hplot <- ggplot(sea_schaefer400_densplot_agg, aes(x = tanh(x_on_z), y = y)) + 
    geom_ribbon(ymin = 0, aes(ymax = y, fill = 'Group', color  = 'Group'), 
                alpha = .5) + 
    geom_ribbon(data = sea_schaefer400_densplot[id == an_id, ], 
                ymin = 0, aes(ymax = y, fill = 'ID', color  = 'ID'), 
                alpha = .5) + 
    scale_fill_manual(aesthetics = c('color','fill'), breaks = c('Group', 'ID'), labels = c('Group', 'Participant'), values = apal[c(2,4)], name = 'Data') +
    facet_wrap(~sess, ncol = 2) + 
    labs(x = 'correlation', y = 'density') + 
    coord_cartesian(xlim = c(-1, 1), ylim = c(0, .5)) + 
    jftheme
  print(hplot)
}
```

# Modeling

We are interested in stability and variability for each network. For each participant, we have multiple sessions, and within each session, we have multiple parcel-parcel pairs that provide information about the within-network connectivity. We can use the fact that we have multiple indicators of within-network connectivity to estimate the between-person variability, as well as the within-person (session-to-session) variability as distinct from measurement error (we assume that each parcel-parcel functional connectivity estimate in a network is an estimate of that network's connectivity)<sup>\*</sup>.

\* This assumption means that we essentially treat differences in the FC between one pair and another as measurement error.

We can compute an ICC that describes both within-person and between-person variability by using a 3 level model. First, I subset the data for a single network. I then build an intercept-only model, allowing the intercept to vary by participant-ID, and by session within each ID. I want to make sure that the intercept is not just the mean across all parcel-pairs, even though the pairs are within-hemisphere. This is because what is typically done (according to Nessa) is that the FC is computed within hemisphere and then averaged across the two hemispheres. To accomplish this we can just inlucde a dummy code for left versus right hemisphere, where `RH = -1` and `LH = 1`. We should let this vary per-person and per-person-session to ensure we accomplish the same thing as if we had computed this separately for each person-session.

$$
\begin{align}
z &= \beta_{0jk} + \beta_{1jk}\text{H}_{ijk} + \epsilon_{ijk} \\
\beta_{0jk} &= \pi_{00k} + \nu_{0jk} \\
\beta_{1jk} &= \pi_{10k} + \nu_{1jk} \\
\pi_{00k} &= \gamma_{000} + \upsilon_{00k} \\
\pi_{10k} &= \gamma_{100} + \upsilon_{10k}
\end{align}
$$

$$
\begin{align}
z = &\gamma_{000} + \upsilon_{00k}  + \nu_{0jk} + \\
&(\gamma_{100} + \upsilon_{10k} + \nu_{1jk})\text{H}_{ijk} + \\
&\epsilon_{ijk}
\end{align}
$$
Where $z$ is the measure of functional connectivity, and $i$ indexes observations within each session, $j$, for each participant $k$. This means that we are able to estimate variance in per-person deviations ($\upsilon_{00k}$) from the network mean-connectivity ($\gamma_{000}$), per-session-deviations ($\nu_{0jk}$) from those per-person deviations, and the residual not explained by variability over persons or person-sessions ($\epsilon_{ijk}$). All these are adjusted by the the effect of hemisphere at every level.

## Testing these out

I want to make sure that these models are correct, so I'll compare the variance portions, and total variance, between the two models.

```{r}
library(lme4)
networks <- unique(sea_schaefer400_7_withinnet$net1)
this_net <- networks[[2]]
this_net_dt <- sea_schaefer400_7_withinnet[net1 == this_net] 

model_dir <- 'models'
test_model_list <- list(test_2l = list(fn = file.path(model_dir, 'test_2l.RDS'),
                                         form = z ~ 1 + H + (1 + H || id)),
                          test_3l = list(fn = file.path(model_dir, 'test_3l.RDS'),
                                         form = z ~ 1 + H + (1 + H || id/sess)),
                          test_3l_noh = list(fn = file.path(model_dir, 'test_3l_noh.RDS'),
                                             form = z ~ 1 + (1 | id/sess)))
cl <- parallel::makePSOCKcluster(max(c(ncores - 1), 1))

test_model_fits <- parallel::parLapply(cl = cl, test_model_list, function(model_list, d){
  library(lme4)
  if(!file.exists(model_list[['fn']])){
    f <- model_list[['form']]
    fit <- lmer(f, data = d)
    saveRDS(fit, model_list[['fn']])
  } else {
    fit <- readRDS(model_list[['fn']])
  }
  return(fit)
}, d = this_net_dt)

try(parallel::stopCluster(cl))
```

```{r}
three_level <- test_model_fits$test_3l
three_level_noh <- test_model_fits$test_3l_noh

summary(three_level)
summary(three_level_noh)
lll_varcorr <- VarCorr(three_level)
lll_varcorr_noh <- VarCorr(three_level_noh)

report_df <- data.frame(
  stat = c('id_var', 'sess_var', 'resid_var', 'total_var'),
  three_level = c(lll_varcorr$id.1['(Intercept)','(Intercept)'],
                  lll_varcorr$sess.id.1['(Intercept)','(Intercept)'],
                  sigma(three_level)^2,
                  sum(unlist(lapply(lll_varcorr, diag))) + sigma(three_level)^2),
  three_level_noh = c(lll_varcorr_noh$id['(Intercept)','(Intercept)'],
                      lll_varcorr_noh$`sess:id`['(Intercept)','(Intercept)'],
                      sigma(three_level_noh)^2,
                      sum(unlist(lapply(lll_varcorr_noh, diag))) + sigma(three_level_noh)^2))

report_df$three_level_perc <- 
  sprintf('%.1f%%', report_df$three_level/report_df$three_level[[4]]*100)
report_df$three_level_noh_perc <- 
  sprintf('%.1f%%', report_df$three_level_noh/report_df$three_level_noh[[4]]*100)
report_df$three_level_RE_perc <- 
  c(sprintf('%.1f%%', report_df$three_level[1:2]/sum(report_df$three_level[1:2])*100), '-', '-')
report_df$three_level_RE_noh_perc <- 
  c(sprintf('%.1f%%', report_df$three_level_noh[1:2]/sum(report_df$three_level_noh[1:2])*100), '-', '-')
knitr::kable(report_df, digits = 5)
```

## Fit for each network {.tabset}

```{r}
networks <- unique(sea_schaefer400_7_withinnet$net1)

netlist <- lapply(networks, function(this_net){
  return(list(network = this_net, d = sea_schaefer400_7_withinnet[net1 == this_net]))
})

cl <- parallel::makePSOCKcluster(max(c(ncores - 1, 1)))
model_fits <- parallel::parLapply(cl = cl, netlist, function(anet){
  this_net <- anet[['network']]
  this_net_dt <- anet[['d']]
  model_dir <- 'models'
  model_fit_fn <- file.path(model_dir, paste0('lmer_fit-3l-', this_net, '.RDS'))
  library(lme4)
  if(!file.exists(model_fit_fn)){
    fit <- lmer(z ~ 1 + H + (1 + H || id/sess), data = this_net_dt)
    saveRDS(fit, model_fit_fn)
  } else {
    fit <- readRDS(model_fit_fn)
  }
  return(fit)
})
try(parallel::stopCluster(cl))

proportion_variance_tables <- lapply(model_fits, function(model_fit){
  vc <- VarCorr(model_fit)
  id_v <- vc$id.1['(Intercept)','(Intercept)']
  idsess_v <- vc$sess.id.1['(Intercept)','(Intercept)']
  s_2 <- sigma(model_fit)^2
  total_RE <- sum(unlist(lapply(vc, diag)))
  other_RE <- total_RE - id_v - idsess_v
  total <- total_RE + s_2
  return(data.frame(source = rep(c('ID', 'ID/Session', 'Other RE', 'Residual'),2),
                    out_of = factor(c(rep('total', 4), rep('RE', 4)), levels = c('total', 'RE')),
                    percent = c(c(id_v, idsess_v, other_RE, s_2)*100 / total,
                                c(id_v, idsess_v, other_RE, NA)*100 / total_RE)))
})
```

The plots on the left, below, show model-expected functional connectivity pearson correlations for each participant, for each session, overlayed on the raw data (one point per parcel, per session, per participant). A line for each participant's model-expected mean across all sessions is overlayed on this. The right plot shows proportions of variance accounted for by the random effect estimates as a proportion of both total variance, and total random effects (RE) variance. The total RE variance includes individual means (ID), individual means per session (ID/Session), and the difference in connectivity between right and left hemispheres (we treat this as a nuisance variable, essentially).

```{r, results='asis', fig.height=3.5, fig.width=8}
library(patchwork)

max_points <- unlist(sea_schaefer400_7_withinnet[, .N, by = net1][, list(max = max(N))])

plot_percents <- function(percent_table){
  ggplot(percent_table, aes(y = percent, x = out_of, fill = source)) + 
    geom_col(position = 'stack') + 
    scale_fill_manual(breaks = c('ID', 'ID/Session', 'Other RE', 'Residual'),
                      values = apal[c(4,3,2,1)]) +
    scale_y_continuous(breaks = c(0, 20, 40, 60, 80, 100), labels = paste0(c(0, 20, 40, 60, 80, 100), '%')) + 
    labs(x = 'Variance (denominator)', y = '', fill = 'Variance source') +
    jftheme
}

plot_predictions <- function(amodel, max_points){
  adt <- as.data.table(amodel@frame)
  adt[, wave := factor(as.numeric(gsub('ses-(\\d+)', '\\1', sess)))]
  newdata <- unique(adt, by = c('id', 'sess', 'wave'))[, c('H', 'z') := list(0, NULL)]
  newdata$z_prime <- predict(amodel, newdata = newdata)
  newdata$z_prime_id <- predict(amodel, newdata = newdata, re.form = ~(1|id))
  point_alpha <- .125 - dim(adt)[[1]]/max_points/8 + .01
  ggplot(newdata, aes(x = wave, y = tanh(z_prime), group = id)) + 
    #geom_violin(data = adt, aes(group = NULL, y = tanh(z)), size = 0, alpha = .5, fill = apal[[1]]) +
    geom_point(data = adt, aes(group = NULL, y = tanh(z)), alpha = point_alpha, color = apal[[1]], position = position_jitter(), size = .5) +
    geom_point(color = apal[[3]], alpha = 1) + 
    geom_line(color = apal[[3]]) + 
    geom_rug(data = unique(newdata, by = 'id'), aes(y = z_prime_id, x = NULL), color = apal[[4]], alpha = 1, sides = 'tr', length = unit(0.03, "npc")) + 
    geom_hline(yintercept = 0, color = apal[[1]]) + 
    coord_cartesian(ylim = c(-.025, .65), xlim = c(1, 10)) + 
    labs(y = 'FC correlation', x = 'Session') + 
    jftheme
}

for(i in 1:length(model_fits)){
  model_fit <- model_fits[[i]]
  network_name <- networks[[i]]
  cat('\n\n### ', network_name, '{.tabset}\n\n') 
  cat('\n\n#### Plot\n\n')
  print(plot_predictions(model_fit, max_points = max_points) + plot_percents(proportion_variance_tables[[i]]) +
          plot_layout(ncol = 2, widths = c(4,1)))
  cat('\n\n#### Table (%)\n\n')
  print(knitr::kable(tidyr::spread(proportion_variance_tables[[1]], out_of, percent), digits = 1))

}
```

